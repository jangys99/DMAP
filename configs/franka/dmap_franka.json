{
    "env_name": "AdaptFrankaGraspEnv",
    "env_config": {
        "render": true,
        "num_memory_steps": 30
    },
    "num_trainer_workers": 0, 
    "policies_to_train": {
        "policy": true
    },
    "policy_classes": {
        "policy": "sac"
    },
    "policy_configs": {
        "policy": {
            "policy_model": {
                "custom_model": "dmap_policy",
                "embedding_size": 4,
                "fcnet_activation": "relu",
                "feature_convnet_params": [],
                "feature_fcnet_hiddens": [128, 32],
                "policy_hiddens": [32, 32]
            },
            "Q_model": {
                "custom_model": "oracle_q_adapt",
                "fcnet_activation": "relu",
                "encoder_hiddens": [256, 128],
                "encoding_size": 4,
                "q_hiddens": [128, 128]
            },
            "optimization": {
                "actor_learning_rate": 3e-4,
                "critic_learning_rate": 3e-4,
                "entropy_learning_rate": 3e-4
            },
             "normalize_actions": true,
             "no_done_at_end": false,
             "n_step": 1,
             "timesteps_per_iteration": 1500,
             "buffer_size": 1000000,
             "learning_starts": 10000
        }
    },
    "agent_policy_dict": {
        "agent": "policy"
    },
    "gamma": 0.995,
    "rollout_fragment_length": 1,
    "train_batch_size": 256,
    "lr": 1e-4,
    "num_gpus": 0,

    "extra_trainer_params": {
        "framework": "torch",
        "seed": 0
    },

    "trainer_class": "sac",
    "episodes_total": 1000,
    "logdir": "output",
    "trial_name": "dmap_franka",
    "checkpoint_freq": 100,
    "restore_checkpoint_path": null
}